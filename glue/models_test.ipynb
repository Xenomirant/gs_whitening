{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"this is a sample text\", \"another text about lorem ipsum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  9226,    16,    10,  7728,  2788,     2,     1,     1,     1],\n",
       "        [    0, 30303,  2788,    59, 36307,   119,  1437,  7418,   783,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(**ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = res.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from torch import Tensor\n",
    "from typing import Any, Optional\n",
    "\n",
    "\n",
    "class Whitening2d(nn.Module):\n",
    "    def __init__(self, \n",
    "        num_features,\n",
    "        iterations=4, \n",
    "        use_running_stats_train=True,\n",
    "        use_batch_whitening=False,\n",
    "        use_only_running_stats_eval=False,\n",
    "        track_running_stats: bool = True,\n",
    "        momentum: Optional[float] = 0.1,\n",
    "        affine: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "                ):\n",
    "        super(Whitening2d, self).__init__()\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        self.num_features=num_features\n",
    "        self.iterations=iterations\n",
    "        self.use_batch_whitening=use_batch_whitening\n",
    "        self.use_running_stats_train=use_running_stats_train\n",
    "        self.use_only_running_stats_eval=use_only_running_stats_eval\n",
    "        self.track_running_stats=track_running_stats\n",
    "        self.momentum=momentum\n",
    "        self.affine=affine\n",
    "\n",
    "        if self.affine:\n",
    "            self.weight=torch.nn.Parameter(torch.empty(num_features, **factory_kwargs))\n",
    "            self.bias=torch.nn.Parameter(torch.empty(num_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter(\"weight\", None)\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        \n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer(\n",
    "                \"running_mean\", torch.zeros(num_features, **factory_kwargs)\n",
    "            )\n",
    "            self.register_buffer(\n",
    "                \"running_covariance\", torch.ones(num_features, num_features, **factory_kwargs)\n",
    "            )\n",
    "            self.register_buffer(\n",
    "                \"running_whitening\", torch.ones(num_features, num_features, **factory_kwargs)\n",
    "            )\n",
    "            self.running_mean: Optional[Tensor]\n",
    "            self.running_covariance: Optional[Tensor]\n",
    "            self.running_whitening: Optional[Tensor]\n",
    "        else:\n",
    "            self.register_buffer(\"running_mean\", None)\n",
    "            self.register_buffer(\"running_covariance\")\n",
    "            self.running_whitening(\"running_whitening\")\n",
    "        self.reset_parameters()\n",
    "\n",
    "        \n",
    "    def reset_running_stats(self) -> None:\n",
    "        if self.track_running_stats:\n",
    "            self.running_mean.zero_()  \n",
    "            self.running_covariance.fill_(1)\n",
    "            self.running_whitening.fill_(1)\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            torch.nn.init.ones_(self.weight)\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def update_running_statistic(self, running_statistic, value):\n",
    "        cur = getattr(self, running_statistic,)\n",
    "        setattr(self, running_statistic, \n",
    "                (1-self.momentum)*cur + self.momentum*value\n",
    "                )\n",
    "\n",
    "    def forward_train(self, x):\n",
    "        \n",
    "        batch_size, w_dim = x.size(0), x.size(-1)\n",
    "        \n",
    "        m_r = x.mean(1, keepdim=True)\n",
    "        if self.use_running_stats_train:\n",
    "            m = (1-self.momentum)*self.running_mean + self.momentum*m_r\n",
    "        else:\n",
    "            m = m_r\n",
    "        \n",
    "        xn = x - m\n",
    "\n",
    "        eye, sigma_r = self.calc_eye_sigma(xn, w_dim=w_dim, batch_size=batch_size)\n",
    "        if self.use_running_stats_train:\n",
    "            sigma = (1-self.momentum)*self.running_covariance[None, :, :] + self.momentum*sigma_r\n",
    "        else:\n",
    "            sigma = sigma_r\n",
    "\n",
    "        wh_matrix = self.whiten_matrix(sigma=sigma, eye=eye)\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            self.update_running_statistic(\"running_mean\", m_r.mean(dim=0))\n",
    "            self.update_running_statistic(\"running_covariance\", sigma_r.mean(dim=0))\n",
    "            self.update_running_statistic(\"running_whitening\", wh_matrix.mean(dim=0))\n",
    "\n",
    "        decorrelated = torch.bmm(xn, wh_matrix)\n",
    "        return decorrelated\n",
    "    \n",
    "    @torch.no_grad\n",
    "    def forward_test(self, x):\n",
    "\n",
    "        batch_size, w_dim = x.size(0), x.size(-1)\n",
    "\n",
    "        if self.use_only_running_stats_eval:\n",
    "            xn = x - self.running_mean\n",
    "            decorrelated = torch.bmm(xn, \n",
    "                                     einops.repeat(self.running_whitening, \"feats1 feats2 -> batch feats1 feats2\", batch=batch_size), \n",
    "                                     )\n",
    "            return decorrelated\n",
    "        \n",
    "        m = x.mean(1, keepdim=True)\n",
    "        m = (1-self.momentum)*self.running_mean + self.momentum*m\n",
    "\n",
    "        xn = x - m\n",
    "\n",
    "        eye, sigma = self.calc_eye_sigma(xn, w_dim=w_dim, batch_size=batch_size)\n",
    "        sigma = (1-self.momentum)*self.running_covariance[None, :, :] + self.momentum*sigma\n",
    "\n",
    "        wh_matrix = self.whiten_matrix(sigma=sigma, eye=eye)\n",
    "        decorrelated = torch.bmm(xn, wh_matrix)\n",
    "        return decorrelated\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.training:\n",
    "            x = self.forward_train(x=x)\n",
    "            return x\n",
    "        x = self.forward_test(x=x)\n",
    "        return x\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def whiten_matrix(self, sigma, eye):\n",
    "        pass\n",
    "\n",
    "    def calc_eye_sigma(self, xn, w_dim, batch_size):\n",
    "        eye = einops.repeat(torch.eye(w_dim).type(xn.type()), \n",
    "                \"feats1 feats2 -> batch feats1 feats2\", batch=batch_size).to(xn.device)\n",
    "        if self.use_batch_whitening:\n",
    "            batch_cov = einops.rearrange(xn, \"batch sequence feats -> (batch sequence) feats\")\n",
    "            sigma = einops.einsum(batch_cov, batch_cov, \n",
    "                                  \"batch_seq feats1, batch_seq feats2 -> feats1 feats2\") / (batch_cov.shape[0] - 1)\n",
    "            sigma = einops.repeat(sigma, \"feats1 feats2 -> batch feats1 feats2\", batch=batch_size)\n",
    "        else:\n",
    "            sigma = einops.einsum(xn, xn, \n",
    "                                  \"batch seq feats1, batch seq feats2 -> batch feats1 feats2\") / (xn.shape[1] - 1)\n",
    "        return eye, sigma\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            \"{num_features}, iterations={iterations}, momentum={momentum}, affine={affine}, \"\n",
    "            \"track_running_stats={track_running_stats}, use_batch_whitening={use_batch_whitening}, \"\n",
    "            \"use_running_stats_train={use_running_stats_train}, use_only_running_stats_eval={use_only_running_stats_eval}\".format(**self.__dict__)\n",
    "        )\n",
    "\n",
    "class Whitening2dIterNorm(Whitening2d):\n",
    "\n",
    "    def whiten_matrix(self, sigma, eye):\n",
    "        trace = sigma.diagonal(offset=0, dim1=-2, dim2=-1).sum(-1)\n",
    "        trace = trace.reshape(sigma.size(0), 1, 1)\n",
    "        sigma_norm = sigma * trace.reciprocal()\n",
    "\n",
    "        projection = eye\n",
    "        for _ in range(self.iterations):\n",
    "            projection = torch.baddbmm(projection, torch.matrix_power(projection, 3), sigma_norm, beta=1.5, alpha=-0.5)\n",
    "        wm = projection.mul_(trace.reciprocal().sqrt())\n",
    "        return wm\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "WH = Whitening2dIterNorm(num_features=75, iterations=4, use_batch_whitening=False, use_only_running_stats_eval=False, use_running_stats_train=False, device=\"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whitening2dIterNorm(75, iterations=4, momentum=0.1, affine=True, track_running_stats=True, use_batch_whitening=False, use_running_stats_train=False, use_only_running_stats_eval=False)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WH.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = WH(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9080, 0.8992, 0.8997,  ..., 0.9000, 0.9001, 0.9004],\n",
       "        [0.8992, 0.9082, 0.9002,  ..., 0.9003, 0.8999, 0.8998],\n",
       "        [0.8997, 0.9002, 0.9082,  ..., 0.8999, 0.9002, 0.9001],\n",
       "        ...,\n",
       "        [0.9000, 0.9003, 0.8999,  ..., 0.9082, 0.9004, 0.8995],\n",
       "        [0.9001, 0.8999, 0.9002,  ..., 0.9004, 0.9084, 0.8999],\n",
       "        [0.9004, 0.8998, 0.9001,  ..., 0.8995, 0.8999, 0.9083]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WH.running_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whitening2dIterNorm(75, iterations=4, momentum=0.1, affine=True, track_running_stats=True, use_batch_whitening=False, use_running_stats_train=False, use_only_running_stats_eval=False)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WH.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 100, 75])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[351], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33.7785, 23.8803, 25.4830,  ..., 24.8048, 24.9052, 25.8465],\n",
       "        [23.8803, 31.8603, 24.9091,  ..., 24.0745, 23.5968, 24.2057],\n",
       "        [25.4830, 24.9091, 33.8999,  ..., 24.6719, 24.9012, 25.5308],\n",
       "        ...,\n",
       "        [24.8048, 24.0745, 24.6719,  ..., 32.0714, 24.2643, 24.0076],\n",
       "        [24.9052, 23.5968, 24.9012,  ..., 24.2643, 32.1149, 24.2961],\n",
       "        [25.8465, 24.2057, 25.5308,  ..., 24.0076, 24.2961, 33.3672]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.permute(0, 2, 1) @ A).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33.7785, 23.8803, 25.4830,  ..., 24.8048, 24.9052, 25.8465],\n",
       "        [23.8803, 31.8603, 24.9091,  ..., 24.0745, 23.5968, 24.2057],\n",
       "        [25.4830, 24.9091, 33.8999,  ..., 24.6719, 24.9012, 25.5308],\n",
       "        ...,\n",
       "        [24.8048, 24.0745, 24.6719,  ..., 32.0714, 24.2643, 24.0076],\n",
       "        [24.9052, 23.5968, 24.9012,  ..., 24.2643, 32.1149, 24.2961],\n",
       "        [25.8465, 24.2057, 25.5308,  ..., 24.0076, 24.2961, 33.3672]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.reshape(-1, 75).T @ A.reshape(-1, 75))/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "A = torch.rand(12, 100, 75)\n",
    "\n",
    "B = A - A.mean(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(62.9139),\n",
       " tensor(62.9044),\n",
       " tensor(63.0548),\n",
       " tensor(63.3632),\n",
       " tensor(62.6881),\n",
       " tensor(63.1737),\n",
       " tensor(63.2783),\n",
       " tensor(62.7499),\n",
       " tensor(62.8380),\n",
       " tensor(62.8024),\n",
       " tensor(62.9698),\n",
       " tensor(63.0622)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TL(x, axis=0) for x in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.bmm(B.permute(0, 2, 1), B) / 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([62.9139, 62.9044, 63.0548, 63.3632, 62.6881, 63.1737, 63.2783, 62.7499,\n",
       "        62.8380, 62.8024, 62.9698, 63.0622])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.diagonal(offset=0, dim1=1, dim2=2).add(-1).pow(2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_loss(output):\n",
    "    output = output - output.mean(dim=1, keepdim=True)\n",
    "    output = torch.bmm(output.permute(0, 2, 1), output)/(output.shape[1] - 1)\n",
    "    tl = output.diagonal(offset=0, dim1=1, dim2=2).add(-1).pow(2).sum(dim=1).mean()\n",
    "    return tl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(62.9139),\n",
       " tensor(62.9044),\n",
       " tensor(63.0548),\n",
       " tensor(63.3632),\n",
       " tensor(62.6881),\n",
       " tensor(63.1737),\n",
       " tensor(63.2783),\n",
       " tensor(62.7499),\n",
       " tensor(62.8380),\n",
       " tensor(62.8024),\n",
       " tensor(62.9698),\n",
       " tensor(63.0622)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[((1-torch.diag(x))**2).sum() for x in C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((768,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.embeddings.LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaIntermediate(\n",
       "  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (intermediate_act_fn): GELUActivation()\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.encoder.layer[1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings\n",
      "encoder.layer.0.output\n",
      "encoder.layer.1.output\n",
      "encoder.layer.2.output\n",
      "encoder.layer.3.output\n",
      "encoder.layer.4.output\n",
      "encoder.layer.5.output\n",
      "encoder.layer.6.output\n",
      "encoder.layer.7.output\n",
      "encoder.layer.8.output\n",
      "encoder.layer.9.output\n",
      "encoder.layer.10.output\n",
      "encoder.layer.11.output\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if name == \"embeddings\" or re.search(\"encoder\\.layer\\.[0-9]+\\.output$\", name):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_classes, cls_dropout=0.1, use_trace_loss=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.layer_losses = 0  # List to store layer-wise losses\n",
    "        self.eff_ranks = {}\n",
    "        self._register_eff_rank_hooks()\n",
    "\n",
    "        if use_trace_loss:\n",
    "            self._register_trace_loss_hooks()\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(cls_dropout),\n",
    "            nn.Linear(768, n_classes))\n",
    "        \n",
    "        if n_classes == 1:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def _register_trace_loss_hooks(self):\n",
    "        \"\"\"Register hooks to calculate and store layer-wise losses\"\"\"\n",
    "        def get_loss_hook(layer_name):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    output = output[0]  # Handle cases where output is a tuple\n",
    "                # Calculate MSE loss between input and output\n",
    "                self.layer_losses += 0 # fix later\n",
    "                return None\n",
    "            return hook\n",
    "\n",
    "        # Register hooks for specific layers\n",
    "        for name, module in self.roberta.named_modules():\n",
    "            if isinstance(module, nn.Linear):  # You can modify this condition to target specific layers\n",
    "                module.register_forward_hook(get_loss_hook(name))\n",
    "\n",
    "    def _register_eff_rank_hooks(self):\n",
    "        \"\"\"Register hooks to calculate and store layer-wise losses\"\"\"\n",
    "        def get_loss_hook(layer_name):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    output = output[0].clone().detach()  # Handle cases where output is a tuple\n",
    "                self.eff_ranks[layer_name] = (\n",
    "                    torch.linalg.matrix_norm(output, ord=\"fro\", dim=(-2, -1)) / torch.linalg.matrix_norm(output, ord=2, dim=(-2, -1))\n",
    "                    ).mean()\n",
    "                return None\n",
    "            return hook\n",
    "\n",
    "        # Register hooks for specific layers\n",
    "        for name, module in self.roberta.named_modules():\n",
    "            if name == \"embeddings\" or re.search(\"encoder\\.layer\\.[0-9]+\\.output$\", name):\n",
    "                module.register_forward_hook(get_loss_hook(name))\n",
    "    \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, **batch):\n",
    "        self.layer_losses = 0  # Clear previous losses\n",
    "        self.eff_ranks = {}\n",
    "        roberta_output = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        pooler = roberta_output[0][:, 0]\n",
    "        logits = self.classifier(pooler)\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(logits.squeeze(), labels)\n",
    "            return {\"loss\": loss, \"logits\": logits, \"layer_losses\": self.layer_losses}\n",
    "        return {\"logits\": logits, \"layer_losses\": self.layer_losses}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaClassifier(n_classes=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[ 0.1355, -0.0559],\n",
       "         [ 0.1264, -0.0002]], grad_fn=<AddmmBackward0>),\n",
       " 'layer_losses': 0}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor(1.8343, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.0.output': tensor(1.3521, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.1.output': tensor(1.1625, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.2.output': tensor(1.1425, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.3.output': tensor(1.1349, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.4.output': tensor(1.1327, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.5.output': tensor(1.1328, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.6.output': tensor(1.1404, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.7.output': tensor(1.1391, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.8.output': tensor(1.1367, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.9.output': tensor(1.1119, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.10.output': tensor(1.1065, grad_fn=<MeanBackward0>),\n",
       " 'encoder.layer.11.output': tensor(1.0817, grad_fn=<MeanBackward0>)}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eff_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_whitening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
